{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPju1S7KQJFpL4ZxqtNITmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chaimaferdia/AIoT-2025/blob/main/Tp01_webscraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "base_url = \"https://arxiv.org/search/?query=machine+learning&searchtype=all&source=header\"\n",
        "\n",
        "papers = []\n",
        "\n",
        "for page in range(0, 25):\n",
        "    print(f\"Scraping page {page+1}...\")\n",
        "    url = f\"{base_url}&start={page*50}\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    results = soup.find_all(\"li\", class_=\"arxiv-result\")\n",
        "\n",
        "    for result in results:\n",
        "\n",
        "        title_tag = result.find(\"p\", class_=\"title is-5 mathjax\")\n",
        "        title = title_tag.text.strip().replace(\"\\n\", \" \").replace(\",\", \";\") if title_tag else \"N/A\"\n",
        "\n",
        "        authors_tag = result.find(\"p\", class_=\"authors\")\n",
        "        authors = authors_tag.text.replace(\"Authors:\", \"\").strip().replace(\"\\n\", \" \").replace(\",\", \";\") if authors_tag else \"N/A\"\n",
        "\n",
        "        category_tag = result.find(\"span\", class_=\"tag is-small is-link tooltip is-tooltip-top\")\n",
        "        category = category_tag.text.strip() if category_tag else \"N/A\"\n",
        "\n",
        "        link_tag = result.find(\"p\", class_=\"list-title is-inline-block\")\n",
        "        link = link_tag.find(\"a\")[\"href\"].strip() if link_tag and link_tag.find(\"a\") else \"N/A\"\n",
        "\n",
        "        papers.append({\n",
        "            \"Title\": \" \".join(title.split()),\n",
        "            \"Authors\": \" \".join(authors.split()),\n",
        "            \"Category\": \" \".join(category.split()),\n",
        "            \"Link\": link\n",
        "        })\n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "df = pd.DataFrame(papers)\n",
        "df.to_csv(\"arxiv_papers.csv\", index=False, encoding=\"utf-8-sig\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XZtHlfDAcScC",
        "outputId": "fa539fc6-63b8-451f-92cc-71f1442913c9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1...\n",
            "Scraping page 2...\n",
            "Scraping page 3...\n",
            "Scraping page 4...\n",
            "Scraping page 5...\n",
            "Scraping page 6...\n",
            "Scraping page 7...\n",
            "Scraping page 8...\n",
            "Scraping page 9...\n",
            "Scraping page 10...\n",
            "Scraping page 11...\n",
            "Scraping page 12...\n",
            "Scraping page 13...\n",
            "Scraping page 14...\n",
            "Scraping page 15...\n",
            "Scraping page 16...\n",
            "Scraping page 17...\n",
            "Scraping page 18...\n",
            "Scraping page 19...\n",
            "Scraping page 20...\n",
            "Scraping page 21...\n",
            "Scraping page 22...\n",
            "Scraping page 23...\n",
            "Scraping page 24...\n",
            "Scraping page 25...\n"
          ]
        }
      ]
    }
  ]
}